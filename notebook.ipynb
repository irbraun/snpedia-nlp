{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import mwclient\n",
    "\n",
    "import cleaning\n",
    "import querying\n",
    "\n",
    "sys.path.append(\"../oats\")\n",
    "from oats.utils.utils import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161\n",
      "['A4GALT', 'AANAT', 'AARS', 'AARS2', 'ABCA1', 'ABCA12', 'ABCA3', 'ABCA4', 'ABCA7', 'ABCB1']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of the genes on SNPedia.\n",
    "site = mwclient.Site('bots.snpedia.com', path=\"/\")\n",
    "snpedia_gene_names = [page.name for page in site.Categories[\"Is_a_gene\"]]\n",
    "print(len(snpedia_gene_names))\n",
    "print(snpedia_gene_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at just a subset of them for now.\n",
    "#snpedia_gene_names = snpedia_gene_names[1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/oats/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# We might need to scrape for all the gene names in SNPEedia, because we can only use the ones mentioned in KEGG.\n",
    "kegg_filename = \"/Users/irbraun/phenologs-with-oats/outputs/06_30_2020_h15m05s52_r1082/part_1_kegg_groupings.csv\"\n",
    "kegg_df = pd.read_csv(kegg_filename)\n",
    "kegg_df = kegg_df[kegg_df[\"species\"]==\"hsa\"]\n",
    "kegg_gene_names = flatten([x.split(\"|\") for x in kegg_df[\"gene_names\"].values])\n",
    "kegg_gene_names = [g.upper() for g in kegg_gene_names]\n",
    "genes_in_snpedia_and_kegg = list(set(kegg_gene_names).intersection(set(snpedia_gene_names)))\n",
    "print(len(genes_in_snpedia_and_kegg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The web scraping step.\n",
    "gene_num_limit = 1500\n",
    "pause_after = 50\n",
    "genes_to_snps_to_text = defaultdict(dict)\n",
    "for i,gene_name in enumerate(genes_in_snpedia_and_kegg,1):\n",
    "    genes_to_snps_to_text[gene_name] = querying.gene_to_snp_texts(site, gene_name)\n",
    "    if i%pause_after == 0:\n",
    "        time.sleep(10)\n",
    "        print(i)\n",
    "    if i%gene_num_limit == 0:\n",
    "        break\n",
    "print(\"Completed the web scraping step.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producing a dataset in CSV format that shows genes, SNPs, and the text that was cleaned from each page.\n",
    "\n",
    "# Create each row one at a time.\n",
    "row_tuples = []\n",
    "for gene in genes_to_snps_to_text.keys():\n",
    "    for snp,raw_text in genes_to_snps_to_text[gene].items():\n",
    "        cleaned_text = cleaning.clean_raw_page_text(raw_text)\n",
    "        row_tuples.append((gene,snp,cleaned_text))\n",
    "        \n",
    "# Generate the dataframe and subset to only include SNPs that had some amount of text extracted, and save as CSV file.\n",
    "df = pd.DataFrame(row_tuples, columns = [\"gene\",\"snp\",\"text\"])\n",
    "df = df[df[\"text\"] != \"\"]\n",
    "df.to_csv(\"dataset.csv\", index=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a dataset in a format that can be used by the oats package.\n",
    "concatenated_text_dict = {g:\" \".join([text for text in genes_to_snps_to_text[g].values()]) for g in genes_to_snps_to_text}\n",
    "cleaned_text_dict = {g:cleaning.clean_raw_page_text(text) for g,text in concatenated_text_dict.items()}\n",
    "len(cleaned_text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe that has this information in it.\n",
    "row_tuples = []\n",
    "for gene,text in cleaned_text_dict.items():\n",
    "    row_tuples.append((\"hsa\",gene,text))\n",
    "\n",
    "# Generate the dataframe and save as a CSV file.\n",
    "df = pd.DataFrame(row_tuples, columns=[\"species\",\"gene_names\",\"description\"])\n",
    "df[\"gene_synonyms\"] = \"\"\n",
    "df[\"term_ids\"] = \"\"\n",
    "df[\"sources\"] = \"SNPedia\"\n",
    "df.to_csv(\"dataset_for_oats.csv\", index=False)\n",
    "df.head(10)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
